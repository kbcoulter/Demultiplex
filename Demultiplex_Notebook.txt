###################
### DEMULTIPLEX ###
###################

#####################################
### 1.1.1 Prelim Data Exploration ###
#####################################

~ Escaped the evil login node:
    $ srun --account=bgmp --partition=bgmp --time=1:00:00 --pty bash

~ Naviagted:
    $ cd /projects/bgmp/shared/2017_sequencing

1. Which files contain the indexes, and which contain the paired end reads containing the biological data of interest. 
    R1 -> Bio Read 1 
    R2 -> Index Read 1
    R3 -> Index Read 2
    R4 -> Bio Read 2

2. Determine the length of the reads in each file.
    R1 -> 101: $ zcat 1294_S1_L008_R1_001.fastq.gz | head -2 | tail -1 | wc -c
    R2 -> 8: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -2 | tail -1 | wc -c
    R3 -> 8: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -2 | tail -1 | wc -c
    R4 -> $ zcat 1294_S1_L008_R4_001.fastq.gz | head -2 | tail -1 | wc -c
    Note: Subtract 1 from all results to account for the newline character.

3. Determine the phred encoding for these data.
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R1_001.fastq.gz | head -100 | grep -c "<" -
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -100 | grep -c "<" 
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R3_001.fastq.gz | head -100 | grep -c "<" 
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R4_001.fastq.gz | head -100 | grep -c "<" 


###############################
### 1.1.2 His plot Creation ###
###############################

~ $ mamba create -n demulti_env
  $ mamba install python # Python version 3.13.5 
  $ mamba install numpy # Sidenote -> Why does VSCode never like my numpy imports?
  $ mamba install matplotlib

~ Created a Python Script to generate the histograms... need to run on test files first...
    UPDATE:
        Test files look good. Updated the readfile to read non-gzipped files -> Changing back for slurm. 
        $ python qual_by_nuc.py -f ../TEST-input_FASTQ/S1_TEST_R1_001.fastq -k 12 -o TESTINGR1
        
~ Created a slurm script to generate the histogram for all 4 of our files... 
    With this script, we still need to run 4 times, just commenting out the files we dont want before submitting each job. 

~ Copied Bioinfo.py V0.4 into this repo:
  $ scp ./bioinfo.py hpc:/projects/bgmp/kcoulter/bioinfo/Bi622/Demultiplex

~ JOB IDS FOR REAL DATA JOBS (SBATCH):
    SOMETHING IS WRONG/UNEXPECTED W/ FILES... OH NONE OF THEM ARE GZIPPED... Changed to regular file opening and the script ran as expected. 

    Things look good right now...

    REAL JOB IDS: 
    R1: Submitted batch job 36716246
        Command being timed: "./qual_by_nuc.py -f R1FQ -k 101 -o R1_FASTQ"
        User time (seconds): 10208.71
        System time (seconds): 70.96
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 2:51:44
        Exit status: 0
    R2: Submitted batch job 36716245
        Command being timed: "./qual_by_nuc.py -f R2FQ -k 8 -o R2_FASTQ"
        User time (seconds): 1052.25
        System time (seconds): 12.79
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 17:47.24
        Exit status: 0
    R3: Submitted batch job 36716244
        Command being timed: "./qual_by_nuc.py -f R3FQ -k 8 -o R3_FASTQ"
        User time (seconds): 1060.77
        System time (seconds): 13.40
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 18:01.33
        Exit status: 0
    R4: Submitted batch job 36716243
        Command being timed: "./qual_by_nuc.py -f R4FQ -k 101 -o R4_FASTQ"
        User time (seconds): 10255.75
        System time (seconds): 45.82
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 2:52:06
        Exit status: 0

### 1.1.3: Setting a logical cutoff###
    Lets start with 5... justification is in answers and prelim data exploration. 

### 1.1.4: How many indexes have undetermined (N) base calls? ###
    FASTQ R2: 3976613 via $ zcat 1294_S1_L008_R2_001.fastq.gz | awk '/^@/ {getline; print}' | grep N | wc -l
    FASTQ R3: 3328051 via $ zcat 1294_S1_L008_R3_001.fastq.gz | awk '/^@/ {getline; print}' | grep N | wc -l

#############################
### 1.2 Algorithm Outline ###
#############################

~ Whats the problem:

We have lane sequencing data from an Illumina sequencer and need to demultiplex the data , meaning we need to separate it into distinct files for our 
different biological reads. Currently, we have four files: Bioread1, Bioread2, Index1, and Index2. When matching the indexes (or barcodes) to their 
respective reads, you end up with two records of the same read, one being the reverse complement, with both reads oriented 5’ to 3’. So, we expect a
corresponding record between Read1 and Read2. To ensure no index hopping has occurred, we need to match the indexes across these FASTQ files, and then 
split these large files into smaller FASTQ files for each matched read. That is, barcode A matches would produce two FASTQ files (Read1 and Read2), 
barcode B matches would produce another two files, etc. To properly separate these reads, we must match the Read1 and Read2 indexes (using the reverse 
complement of the Read2 index) for each FASTQ record. If index hopping occured, the mean quality score is not sufficient, or if the barcode doesn't match 
our key, we have additional output files for these records and counters to track the number of times this occurs. 

~ What would be the output:

        For each matching index pair, there is one Read1 FASTQ file and one Read2 FASTQ file.
        For index-hopping events (non-matching index pairs within our barcode set), there are two additional FASTQ files, one for Read1 (hopping_R1_fastq.txt) and one for Read2 (hopping_R2_fastq.txt).
        Two more FASTQ files are generated when one or both index reads are unknown (contain Ns), fail the quality score threshold, or do not exist in our index set

        This results in the following output:

        <barcode>_R1_fastq.txt for each unique barcode/index
        <barcode>_R2_fastq.txt for each unique barcode/index 
        hopping_R1_fastq.txt
        hopping_R2_fastq.txt
        unknown_R1_fastq.txt
        unknown_R2_fastq.txt
        
        Also, We must output:
            The number of read-pairs with properly matched indexes (per index-pair),
            the number of read pairs with index-hopping observed, 
            the number of index-hopping occurances by index combination,
            and the number of read-pairs with unknown index(es).

~ Outline:

    ##### FUNCTIONS #####

    def reverse_comp(sequence: str) -> str:
        '''Takes a sequence (string) with or without newline characters and returns the reverse compliment of the string without newline characters'''
        return rev_cop
    Input: CATG
    Expected Output: GTAC

    def convert_phred(letter: str) -> int:
        '''Takes a single ASCII character (string) encoded in Phred+33 and returns the quality score value as an integer.'''
        return qscore  
    Input: I
    Expected output: 40

    def mean_qual_score(sequence: str) -> float:
        '''Takes a quality score sequence (string), uses convert_phred function to convert each phred+33 encoding into a integer quality score, then averages the quality score and returns the mean values. '''
        return mean_score
    Input: IIIIIIIIII
    Expected output: 40

    ##### SCRIPT #####

    Create a quality_score_cutoff integer where every index/barcode read with quality score below goes into unknown. 
    Create a barcode_bank with barcode records (known indices) into a dictionary for faster lookup, with key sequence (GTAGCGTA) and value code (B1). 
    Create a match_dict dictionary with the barcode or indices as keys, and match numbers initilizaed to 0.
    Create a hopping_counter initialized to 0.
    Create a hopping_dict dicitonary with nothing in it. The keys will be our Header_additions and the values will be counters initilaized to 1 upon their addition to the list. 
    Create a unkown_counter initialized to 0. 

    ##### PARSE FILES #####

    Open all 4 files, R1, R2, R3, R4 at the same time. We will iteratively take 1 record (4 lines) from R1 and R4, while collecting the respective indices ONLY from R2 and R3.

        ### PER RECORD VALUES ###
        Read1_Bio = R1 -> Bio Read 1
        Read1_Barcode = R2 with stripped newline characters -> Index Read 1
        Read2_Bio = R4 -> Bio Read 2
        Read2_Barcode = reverse_comp R3 with stripped newline characters -> Index Read 2 (we must reverse compliment the R3 barcode... as this read pairs with the reverse compliment).
        Header_Addition = "<Read1_Barcode>-<Read2_Barcode>"
        quality_score = minimum of (mean_quality_score(Read1_Barcode), mean_quality_score(Read2_Barcode))
        barcode_key = = barcode_bank value at key Read1_Barcode

        Append Header_Addition to the 1st line of Read1_Bio and Read2_Bio. 

            If 1 or both of the barcodes are not in barcode_bank or quality_score < quality_score_cutoff: something went wrong and the barcode/index is unknown, or quality score it too poor to be confident
        
                We will add one to the unknown_counter.

                If unknown_R1_fastq.txt anf unknown_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file unknown_R1_fastq.txt
                    Write Read2_Bio record into the fastq file unknown_R2_fastq.txt
                else:
                    Write our Read1_Bio record into a new fastq file titled unknown_R1_fastq.txt
                    Write our Read2_Bio record into a new fastq file titled unknown_R2_fastq.txt


            Else, If the R2 barcode matches the R3 barcodes: we know that the reads match valid barcodes:

                For this barcode key, we will add one to the match_dict dictionary score. 

                If <barcode_key>_R1_fastq.txt and <barcode_key>_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file <barcode_key>_R1_fastq.txt
                    Write Read2_Bio record into the fastq file <barcode_key>_R2_fastq.txt
                else:
                    Write Read1_Bio record into a new fastq file titled <barcode_key>_R1_fastq.txt
                    Write Read2_Bio record into a new fastq file titled <barcode_key>_R2_fastq.txt


            Else: the R2 and R3 Barcodes must not match, both barcodes are in barcode_bank, and quality_score >= quality_score_cutoff, we know that index hopping occured:

                We will add one to the hopping_counter.
                For our Header_Addition, we will add one to the hopping_dict dictionary score or initialize it to 1 if it does not currently exist.

                If hopping_R1_fastq.txt and hopping_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file hopping_R1_fastq.txt
                    Write Read2_Bio record into the fastq file hopping_R2_fastq.txt
                else:
                    Write Read1_Bio record into a new fastq file titled hopping_R1_fastq.txt
                    Write Read2_Bio record into a new fastq file titled hopping_R2_fastq.txt

    return (match_dict_counter, unknown_counter, hopping_counter, hopping_dict)

# NEED TO DOUBLE CHECK R3 OUTPUT MAKES SENSE... -> LABEL R4 WITH R2 BARCODE

########################
### 3 Demultiplex.py ###
########################

#############################
# $ mamba create -n demultiplex
# $ mamba activate demultiplex
# $ mamba install python # Python version 3.13.5
# $ mamba install numpy
#############################

Reverse comp of string: 

 complement_map = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C',
                      'a': 't', 't': 'a', 'c': 'g', 'g': 'c'}

~ Stopped, output report writing is not as efficient as it should/could be. Lets revise this later...

~ Output writing revised... lost track of newline chars
    Unknown writing was not functioning as expected...
    Lost list index and was calling w/ newline, so was doubling up

!! POTENTIAL ISSUE: !!
    Read1_Barcode = Read1_Barcode.strip()
    Read2_Barcode = reverse_comp(Read2_Barcode) # Ignore warnings, this works ? 

    Not sure what the warnings here are... is it because my function has two possible returned data types?
    SOLUTION: This is ok. The return option that will generate the warning will break before we reach that point in the script. 
        This is fine to keep, but the warning should not be suppressed.

    Note: I still need to add unit tests to the code...

### REAL DATA ###
#r1 = "/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz"
#r2 = "/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz"
#r3 = "/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz"
#r4 = "/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R4_001.fastq.gz"




    

