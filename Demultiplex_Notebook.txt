###################
### DEMULTIPLEX ###
###################

#####################################
### 1.1.1 Prelim Data Exploration ###
#####################################

~ Escaped the evil login node:
    $ srun --account=bgmp --partition=bgmp --time=1:00:00 --pty bash

~ Naviagted:
    $ cd /projects/bgmp/shared/2017_sequencing

1. Which files contain the indexes, and which contain the paired end reads containing the biological data of interest. 
    R1 -> Bio Read 1 
    R2 -> Index Read 1
    R3 -> Index Read 2
    R4 -> Bio Read 2

2. Determine the length of the reads in each file.
    R1 -> 101: $ zcat 1294_S1_L008_R1_001.fastq.gz | head -2 | tail -1 | wc -c
    R2 -> 8: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -2 | tail -1 | wc -c
    R3 -> 8: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -2 | tail -1 | wc -c
    R4 -> $ zcat 1294_S1_L008_R4_001.fastq.gz | head -2 | tail -1 | wc -c
    Note: Subtract 1 from all results to account for the newline character.

3. Determine the phred encoding for these data.
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R1_001.fastq.gz | head -100 | grep -c "<" -
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R2_001.fastq.gz | head -100 | grep -c "<" 
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R3_001.fastq.gz | head -100 | grep -c "<" 
    Quality score contains < chatracters, which only exist in Phred33, therefore we have phred33: $ zcat 1294_S1_L008_R4_001.fastq.gz | head -100 | grep -c "<" 

###############################
### 1.1.2 His plot Creation ###
###############################

~ $ mamba create -n demulti_env
  $ mamba install python # Python version 3.13.5 
  $ mamba install numpy # Sidenote -> Why does VSCode never like my numpy imports?
  $ mamba install matplotlib

~ Created a Python Script to generate the histograms... need to run on test files first...
    UPDATE:
        Test files look good. Updated the readfile to read non-gzipped files -> Changing back for slurm. 
        $ python qual_by_nuc.py -f ../TEST-input_FASTQ/S1_TEST_R1_001.fastq -k 12 -o TESTINGR1
        
~ Created a slurm script to generate the histogram for all 4 of our files... 
    With this script, we still need to run 4 times, just commenting out the files we dont want before submitting each job. 

~ Copied Bioinfo.py V0.4 into this repo:
  $ scp ./bioinfo.py hpc:/projects/bgmp/kcoulter/bioinfo/Bi622/Demultiplex

~ JOB IDS FOR REAL DATA JOBS (SBATCH):
    sbatch qual_by_nuc_slurm.sh R1: Submitted batch job 36694919
    sbatch qual_by_nuc_slurm.sh R2: Submitted batch job 36694920
    sbatch qual_by_nuc_slurm.sh R3: Submitted batch job 36694922
    sbatch qual_by_nuc_slurm.sh R4: Submitted batch job 36694923

    JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
    36694923      bgmp qual_by_ kcoulter  R       1:24      1 n0349
    36694919      bgmp qual_by_ kcoulter  R       4:16      1 n0349

    SOMETHING IS WRONG/UNEXPECTED W/ FILES... OH NONE OF THEM ARE GZIPPED... Changed to regular file opening and the script ran as expected. 

    `Traceback (most recent call last):
    File "/gpfs/projects/bgmp/kcoulter/bioinfo/Bi622/Demultiplex/Assignment-the-first/./qual_by_nuc.py", line 26, in <module>
        for index_line, line_data in enumerate(fastq):
                                    ~~~~~~~~~^^^^^^^
    File "/gpfs/home/kcoulter/miniforge3/envs/demulti_env/lib/python3.13/gzip.py", line 353, in read1
        return self._buffer.read1(size)
            ~~~~~~~~~~~~~~~~~~^^^^^^
    File "/gpfs/home/kcoulter/miniforge3/envs/demulti_env/lib/python3.13/_compression.py", line 68, in readinto
        data = self.read(len(byte_view))
    File "/gpfs/home/kcoulter/miniforge3/envs/demulti_env/lib/python3.13/gzip.py", line 546, in read
        if not self._read_gzip_header():
            ~~~~~~~~~~~~~~~~~~~~~~^^
    File "/gpfs/home/kcoulter/miniforge3/envs/demulti_env/lib/python3.13/gzip.py", line 515, in _read_gzip_header
        last_mtime = _read_gzip_header(self._fp)
    File "/gpfs/home/kcoulter/miniforge3/envs/demulti_env/lib/python3.13/gzip.py", line 475, in _read_gzip_header
        raise BadGzipFile('Not a gzipped file (%r)' % magic)
    gzip.BadGzipFile: Not a gzipped file (b'@K')
    Command exited with non-zero status 1
        Command being timed: "./qual_by_nuc.py -f R3FQ -k 8 -o R3_FASTQ"
        User time (seconds): 1.00
        System time (seconds): 0.06
        Percent of CPU this job got: 282%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.37
        Average shared text size (kbytes): 0
        Average unshared data size (kbytes): 0
        Average stack size (kbytes): 0
        Average total size (kbytes): 0
        Maximum resident set size (kbytes): 59344
        Average resident set size (kbytes): 0
        Major (requiring I/O) page faults: 0
        Minor (reclaiming a frame) page faults: 13786
        Voluntary context switches: 96
        Involuntary context switches: 6
        Swaps: 0
        File system inputs: 0
        File system outputs: 0
        Socket messages sent: 0
        Socket messages received: 0
        Signals delivered: 0
        Page size (bytes): 4096
        Exit status: 1
`
REAL JOB IDS: 2 and 3 FIRST TO CATCH ERROR:
R1: Submitted batch job 36694954
R2: Submitted batch job 36694952
R3: Submitted batch job 36694953
R4: Submitted batch job 36694955

          JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
          36694955      bgmp qual_by_ kcoulter  R       0:27      1 n0349
          36694954      bgmp qual_by_ kcoulter  R       1:05      1 n0349
          36694953      bgmp qual_by_ kcoulter  R       3:45      1 n0349
          36694952      bgmp qual_by_ kcoulter  R       4:27      1 n0349

          Things look good right now...



#############################
### 1.2 Algorithm Outline ###
#############################

~ Whats the problem:

We have lane sequencing data from an Illumina sequencer and need to demultiplex the data , meaning we need to separate it into distinct files for our 
different biological reads. Currently, we have four files: Bioread1, Bioread2, Index1, and Index2. When matching the indexes (or barcodes) to their 
respective reads, you end up with two records of the same read, one being the reverse complement, with both reads oriented 5’ to 3’. So, we expect a
corresponding record between Read1 and Read2. To ensure no index hopping has occurred, we need to match the indexes across these FASTQ files, and then 
split these large files into smaller FASTQ files for each matched read. That is, barcode A matches would produce two FASTQ files (Read1 and Read2), 
barcode B matches would produce another two files, etc. To properly separate these reads, we must match the Read1 and Read2 indexes (using the reverse 
complement of the Read2 index) for each FASTQ record. If index hopping occured, the mean quality score is not sufficient, or if the barcode doesn't match 
our key, we have additional output files for these records and counters to track the number of times this occurs. 

~ What would be the output:

        For each matching index pair, there is one Read1 FASTQ file and one Read2 FASTQ file.
        For index-hopping events (non-matching index pairs within our barcode set), there are two additional FASTQ files, one for Read1 (hopping_R1_fastq.txt) and one for Read2 (hopping_R2_fastq.txt).
        Two more FASTQ files are generated when one or both index reads are unknown (contain Ns), fail the quality score threshold, or do not exist in our index set

        This results in the following output:

        <barcode>_R1_fastq.txt for each unique barcode/index
        <barcode>_R2_fastq.txt for each unique barcode/index 
        hopping_R1_fastq.txt
        hopping_R2_fastq.txt
        unknown_R1_fastq.txt
        unknown_R2_fastq.txt
        
        Also, We must output:
            The number of read-pairs with properly matched indexes (per index-pair),
            the number of read pairs with index-hopping observed, 
            the number of index-hopping occurances by index combination,
            and the number of read-pairs with unknown index(es).

~ Outline:

    ##### FUNCTIONS #####

    def reverse_comp(sequence: str) -> str:
        '''Takes a sequence (string) with or without newline characters and returns the reverse compliment of the string without newline characters'''
        return rev_cop
    Input: CATG
    Expected Output: GTAC

    def convert_phred(letter: str) -> int:
        '''Takes a single ASCII character (string) encoded in Phred+33 and returns the quality score value as an integer.'''
        return qscore  
    Input: I
    Expected output: 40

    def mean_qual_score(sequence: str) -> float:
        '''Takes a quality score sequence (string), uses convert_phred function to convert each phred+33 encoding into a integer quality score, then averages the quality score and returns the mean values. '''
        return mean_score
    Input: IIIIIIIIII
    Expected output: 40

    ##### SCRIPT #####

    Create a quality_score_cutoff integer where every index/barcode read with quality score below goes into unknown. 
    Create a barcode_bank with barcode records (known indices) into a dictionary for faster lookup, with key sequence (GTAGCGTA) and value code (B1). 
    Create a match_dict dictionary with the barcode or indices as keys, and match numbers initilizaed to 0.
    Create a hopping_counter initialized to 0.
    Create a hopping_dict dicitonary with nothing in it. The keys will be our Header_additions and the values will be counters initilaized to 1 upon their addition to the list. 
    Create a unkown_counter initialized to 0. 

    ##### PARSE FILES #####

    Open all 4 files, R1, R2, R3, R4 at the same time. We will iteratively take 1 record (4 lines) from R1 and R4, while collecting the respective indices ONLY from R2 and R3.

        ### PER RECORD VALUES ###
        Read1_Bio = R1 -> Bio Read 1
        Read1_Barcode = R2 with stripped newline characters -> Index Read 1
        Read2_Bio = R4 -> Bio Read 2
        Read2_Barcode = reverse_comp R3 with stripped newline characters -> Index Read 2 (we must reverse compliment the R3 barcode... as this read pairs with the reverse compliment).
        Header_Addition = "<Read1_Barcode>-<Read2_Barcode>"
        quality_score = minimum of (mean_quality_score(Read1_Barcode), mean_quality_score(Read2_Barcode))
        barcode_key = = barcode_bank value at key Read1_Barcode

        Append Header_Addition to the 1st line of Read1_Bio and Read2_Bio. 

            If 1 or both of the barcodes are not in barcode_bank or quality_score < quality_score_cutoff: something went wrong and the barcode/index is unknown, or quality score it too poor to be confident
        
                We will add one to the unknown_counter.

                If unknown_R1_fastq.txt anf unknown_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file unknown_R1_fastq.txt
                    Write Read2_Bio record into the fastq file unknown_R2_fastq.txt
                else:
                    Write our Read1_Bio record into a new fastq file titled unknown_R1_fastq.txt
                    Write our Read2_Bio record into a new fastq file titled unknown_R2_fastq.txt


            Else, If the R2 barcode matches the R3 barcodes: we know that the reads match valid barcodes:

                For this barcode key, we will add one to the match_dict dictionary score. 

                If <barcode_key>_R1_fastq.txt and <barcode_key>_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file <barcode_key>_R1_fastq.txt
                    Write Read2_Bio record into the fastq file <barcode_key>_R2_fastq.txt
                else:
                    Write Read1_Bio record into a new fastq file titled <barcode_key>_R1_fastq.txt
                    Write Read2_Bio record into a new fastq file titled <barcode_key>_R2_fastq.txt


            Else: the R2 and R3 Barcodes must not match, both barcodes are in barcode_bank, and quality_score >= quality_score_cutoff, we know that index hopping occured:

                We will add one to the hopping_counter.
                For our Header_Addition, we will add one to the hopping_dict dictionary score or initialize it to 1 if it does not currently exist.

                If hopping_R1_fastq.txt and hopping_R2_fastq.txt exist:
                    Write Read1_Bio record into the fastq file hopping_R1_fastq.txt
                    Write Read2_Bio record into the fastq file hopping_R2_fastq.txt
                else:
                    Write Read1_Bio record into a new fastq file titled hopping_R1_fastq.txt
                    Write Read2_Bio record into a new fastq file titled hopping_R2_fastq.txt

    return (match_dict_counter, unknown_counter, hopping_counter, hopping_dict)

# NEED TO DOUBLE CHECK R3 OUTPUT MAKES SENSE... -> LABEL R4 WITH R2 BARCODE




    

